---
title: "Big Problems for \\color{USCCardinal} Small Networks\\color{black}: Statistical Analysis of Small Networks and Team Performance"
author:
  - "\\textbf{George G Vega Yon}"
  - "Kayla de la Haye \\vspace{-.5cm}"
date: "Social Network Research Group\\linebreak[4]UCI\\linebreak[4]April 29, 2019"
institute:
  - "\\includegraphics[width=.15\\linewidth]{usc.pdf}\\linebreak[4]Department of Preventive Medicine"
output:
  beamer_presentation:
    keep_tex: true
    includes:
      in_header: ergmitos-header.tex
classoption: handout
fontsize: 10pt
aspectratio: 169
nocite: |
  @Csardi2015, @knitr, @rmarkdown, @R, @Handcock2006, @Wasserman1996
bibliography: bibliography.bib
---

```{r setup, include=FALSE}
knitr::knit_hooks$set(smallsize = function(before, options, envir) {
    if (before) {
        "\\scriptsize\n\n"
    } else {
        "\n\\normalsize\n\n"
    }
})
knitr::opts_chunk$set(echo = TRUE, smallsize=TRUE)
```

## Acknowledgements

\begincols
\begincol{.15\linewidth}

\includegraphics[width=.8\linewidth]{ARO_logo.png}

\endcol

\begincol{.84\linewidth}
This material is based upon work support by, or in part by, the U.S. Army Research
Laboratory and the U.S. Army Research Office under grant number W911NF-15-1-0577
\endcol

\endcols


\begincols
\begincol{.84\linewidth}

Computation for the work described in this paper was supported by the University
of Southern California’s Center for High-Performance Computing (https://hpcc.usc.edu).
\endcol

\begincol{.15\linewidth}
\includegraphics[width = 1\linewidth]{usc.pdf}
\endcol
\endcols

We thank members of our MURI research team, USC's Center for Applied Network Analysis, NU's SONIC lab, Garry Robins, Andrew Slaughter, and attendees of the NASN 2018 conference for their comments.


\begin{figure}
\centering
\includegraphics[width=1\linewidth]{muriteams.png}
\end{figure}

## Research Problem

In the context of network science of small teams:

\pause

\large
\centering
What characterizes the social networks that emerge from small teams?\pause

Is there any association between how team networks are structured and their performance?\normalsize

## Research Problem (cont'd)

We are trying to answer these two questions with the following experimental data: \pause

- 42 teams typically made of 4 to 5 mixed-gender teammates.\pause

- Each team completed 1 hour of group tasks, in particular, a set of tasks to measure collective intelligence developed by MIT [@Kim2017].\pause

- We surveyed team members to capture information regarding socio-demographics **and**:\pause
    
    - Social Intelligence (SI domains): Social Perception (measured by RME), Social Accomodation, Social Gregariousness, and Social Awareness\pause 
    
    - Social Networks: Advice Seeking, Leadership, Influence (among others).


## Contents

\tableofcontents

# Part I: Network Structure

## Exponential Random Graph Models (ERGMs)

\begin{figure}
\centering
\includegraphics[height=.7\textheight]{ukfaculty-igraph.png}
\caption{Friendship network of a UK university faculty. Source: \textbf{igraphdata} R package (Csardi, 2015). Figure drawn using the R package \textbf{netplot} (yours truly, https://github.com/usccana/netplot)}
\end{figure}\pause

<!-- \large How can we explain what we see here? \normalsize -->

## ERGMs... the \textit{lingua franca} of SNA

- Seeks to answer the question: \emph{What local social structures gave origin to a given observed graph?}\pause

- The model is centered around a vector of \textbf{sufficient statistics} $\sufstats{}$, and is operationalized as:
  
  \begin{equation}
  	\Prcond{\Graph = \graph}{\params, \Indepvar} = \frac{%
  		\exp{\transpose{\params}\sufstats{\graph, \Indepvar}}%	
  	}{
  		\kappa\left(\params, \Indepvar\right)
  	},\quad\forall \graph\in\GRAPH\label{eq:ergm}
  \end{equation}
  
  Where $\kappa\left(\params, \Indepvar\right)$ is the normalizing constant and equals $\sum_{\graph'\in\GRAPH}\exp{\transpose{\params}\sufstats{\graph', \Indepvar}}$. \pause
  
- The set of sufficient statistics reflects social and psychological mechanisms that are hypothesized to drive the network structure. Figure \autoref{fig:ergm-structs} shows some examples of values in $\sufstats{}$.\pause
  
- In the case of directed networks, $\GRAPH$ has $2^{n(n-1)}$ terms.\pause

- See Wasserman, Pattison, Robins, Snijders, Handcock and others.


## Structures

\def\fig1width{.45\linewidth}
\begin{figure}
\centering
\begin{tabular}{m{.2\linewidth}<\centering m{.4\linewidth}<\raggedright}
\toprule Representation & Description  \\ \midrule
\includegraphics[width=\fig1width]{terms/mutual.pdf} & Mutual Ties (Reciprocity)\linebreak[4]$\sum_{i\neq j}y_{ij}y_{ji}$  \\
\includegraphics[width=\fig1width]{terms/ttriad.pdf} & Transitive Triad (Balance)\linebreak[4]$\sum_{i\neq j\neq k}y_{ij}y_{jk}y_{ik}$  \\
\includegraphics[width=\fig1width]{terms/homophily.pdf} & Homophily\linebreak[4]$\sum_{i\neq j}y_{ij}\mathbf{1}\left(x_i=x_j\right)$ \\
\includegraphics[width=\fig1width]{terms/nodeicov.pdf} & Covariate Effect for Incoming Ties\linebreak[4]$\sum_{i\neq j}y_{ij}x_j$ \\
\includegraphics[width=\fig1width]{terms/fourcycle.pdf} & Four Cycle\linebreak[4]$\sum_{i\neq j \neq k \neq l}y_{ij}y_{jk}y_{kl}y_{li}$  \\
\bottomrule
\end{tabular}
\caption{\label{fig:ergm-structs}Besides of the common edge count statistic (number of ties in a graph), ERGMs allow measuring other more complex structures that can be captured as sufficient statistics. }
\end{figure}

---

\large \textbf{Example of model} \normalsize


\begincols

\begincol{.4\linewidth}

In this network\linebreak

```{r simple-model, echo=FALSE, cache=TRUE, fig.align='center', fig.width=8, fig.height=5, out.width='.9\\linewidth', warning=FALSE, message=FALSE}
set.seed(13)
# x <- ergmito::rbernoulli(4)
x <- structure(c(0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0), .Dim = c(4L, 
4L))
library(sna)
gplot(x, vertex.col = rgb(153, 0, 0, maxColorValue = 255))
```

\pause

We see 4 **edges**, 1 **transitive triad** and **no mutual ties**.

\endcol

\pause

\begincol{.4\linewidth}

The probability function of this model would be

\footnotesize

\begin{equation*}
\Prcond{\Graph = \graph}{\theta} = \frac{\exp{4\theta_{edges} + \theta_{ttriads} \textcolor{lightgray}{+ 0\theta_{mutual}}}}{%
\sum_{\graph'\in\GRAPH} \exp{\transpose{\theta} \sufstats{\graph'}}}
\end{equation*}

\normalsize

\noindent with $\theta = \transpose{[\theta_{edges}\quad \theta_{ttriads} \quad \theta_{mutual}]}$

\endcol

\endcols

```{r simple-model-estimates, cache=TRUE, echo=FALSE}
estimates0 <- ergmito::ergmito(x ~ edges + ttriad + mutual)
estimates0_coefs <- sprintf("%03.2f", coef(estimates0))
```

\pause

\vspace{1cm}

This model has **MLE parameter estimates** of `r estimates0_coefs[1]` (low density), `r estimates0_coefs[2]` (high chance of ttriads), and `r estimates0_coefs[3]` (low chance of mutuality) for the parameters `edges`, `ttriads`, and `mutual` respectively.

## Estimation of ERGMs


- Calculating of the normalizing constant in \eqref{eq:ergm}, $\kappa = \sum_{\graph'\in\GRAPH}\exp{\transpose{\params}\sufstats{\graph', \Indepvar}}$, makes ERGMs difficult to estimate.\pause

- For this reason, statistical methods have focused on avoiding the direct calculation of $\kappa$; most modern methods for estimating ERGMs rely on MCMC.


## Estimation of ERGMs (cont'd) {.t}

Description of the MCMC-MLE algorithm [@Geyer1992] \pause

1.  Make an initial guess of the model parameters $\hat\theta_0$ \pause

2.  While the algorithm doesn't converge, do: \pause
    
    a.  Generate a large sample of graphs from $\Prcond{\Graph = \graph}{\hat\theta_0, \Indepvar}$ using MCMC \pause
    
    b.  Use the simulated sample of graphs **to approximate the normalizing constant**, and so, the likelihood function. And with this approximation update the parameter $\theta_0$ using a Newton-Raphson step. \pause
    
    c.  next iteration\pause 
    
Once it converges, the last value of $\hat\theta_0$ is the MCMC-MLE estimates.\pause The variance approximation is another story.
    

---

\footnotesize

- While significant advances have been made in the area, simulation based models can suffer from \textbf{model degeneracy} [@Handcock2003].\pause

- This occurs when the model parameters \textit{live in a degenerate region}. This impacts directly the MCMC process yielding poor mixing\pause

\begin{figure}
\centering
\includegraphics[height=.6\textheight]{handcock2003-figure5.pdf}
\caption{Model degeneracy. Figure 5 in Handcock (2003)}
\end{figure}\pause

- Model degeneracy is particularly problematic with small networks... (says anyone who has tried to fit one).

\normalsize

## ERGMs for Small Networks

\begin{figure}
\centering
\includegraphics[height=.9\textheight]{plot-graph-4-1.pdf}
\end{figure}

## ERGMs for Small Networks (cont'd)
			
-   In the case of small networks (e.g. at most 6 nodes), the calculation of $\kappa$ becomes computationally feasible.\pause

-   This allows direct calculation of \eqref{eq:ergm}, \textbf{avoiding the need for simulations} and allowing us to obtain Maximum Likelihood Estimates using \textit{standard} optimization techniques.\pause

-   In addition, most of the time samples of small networks include multiple of them, e.g.: Families, Small teams (like our data), Ego-nets, etc.\pause

-   This makes pooled ERGM estimates a natural way of modeling the data: \pause{}

    $$
    \Prcond{\Graph_1 = \graph_1, \dots, \Graph_p = \graph_p}{\params, \Indepvar_1, \dots, \Indepvar_p} = \prod_p\frac{%
    		\exp{\transpose{\params}\sufstats{\graph_p, \Indepvar_p}}%	
    	}{
    		\kappa_p\left(\params, \Indepvar_p\right)
    	}
    $$ 

\pause

How different is this from the "normal" way to fit ERGMs?

## Estimation of ERGM\only<2->{\textcolor{USCCardinal}{ito}}s (cont'd) {.t}

Description of the \textcolor<2->{lightgray}{MCMC-}\textcolor<2->{USCCardinal}{MLE} algorithm \textcolor<2->{lightgray}{(Geyer and Thompson, 1992)}

1.  Make an initial guess of the model parameters $\hat\theta_0$

2.  While the algorithm doesn't converge, do:
    
    a.  \textcolor<2->{lightgray}{Simulate $B$ graphs from $\Prcond{\Graph = \graph}{\hat\theta_0, \Indepvar}$ using MCMC}
    
    b.  \textcolor<2->{lightgray}{Use the simulated sequence of graphs to approximate the likelihood function. And with this approximation} \textcolor<2->{USCCardinal}{update the parameter $\theta_0$ using a Newton-Raphson step}.
    
    c.  next iteration\pause\pause

By skipping the MCMC part we:\pause

1.  are able to get MLE estimates directly,\pause

2.  *avoid the degeneracy problem* latent in MCMC, and\pause

3.  obtain *more accurate* (exact) estimates *faster*. \pause

We have implemented  this and more in the `ergmito` R package

---

Sidetrack...

\begin{minipage}[c]{1\linewidth}
\large \textbf{ito, ita}: From the latin -\textit{\=ittus}. suffix in Spanish used to denote small or affection. e.g.:

\hspace{.5cm} \textit{¡Qué lindo ese perr\textcolor{USCCardinal}{\textbf{ito}}!} / \textit{What a beautiful little dog!}

\hspace{.5cm} \textit{¿Me darías una tac\textcolor{USCCardinal}{\textbf{ita}} de azúcar?} / \textit{Would you give me a small cup of sugar?}
\normalsize
\end{minipage}\pause

\alert{Special thanks to George Barnett who proposed the name during the 2018 NASN!}

## Features of `ergmito`



This (\includegraphics[width=.1\linewidth]{lifecycle-experimental-orange.pdf}) R package has the following features\pause

- Built on top of [**statnet**](https://statnet.org)'s [`ergm`](https://github.com/statnet/ergm) R package [@hunter2008; @Handcock2018].\pause

- Allows estimating ERGMs for small networks (less than 7 and perhaps 6)[^whyupto6] via MLE.\pause

- Implements pooled ERGM models.\pause

- Includes a simulation function for efficiently drawing samples of small networks, and by **efficiently** we mean **fast**. 



[^whyupto6]: A directed graph of size 6 has a support set with $2^{6\times(6 - 1)} = 1,073,741,824$ elements.

## `ergmito` example

```{r loading-fivenets, cache=TRUE}
library(ergmito)
data(fivenets, package = "ergmito")
```

```{r plotfivenets, warning=FALSE, message=FALSE, echo=FALSE, fig.width=6, fig.height=3, out.width='.5\\linewidth', fig.align='center', cache=TRUE}
library(sna)
library(network)
op <- par(mfrow = c(2, 3), mai=rep(0, 4), oma = rep(0, 4))
USCCARDINAL <- rgb(153, 0, 0, maxColorValue = 255)
ans <- lapply(fivenets, function(f) {
  gplot(
    f,
    vertex.cex = 2,
    vertex.col = c("white", USCCARDINAL)[
      get.vertex.attribute(f, "female") + 1
    ]
    )
  })
plot.new()
plot.window(xlim = c(0, 1), ylim = c(0, 1))
legend("center", fill = c("white", USCCARDINAL), legend = c("Male", "Female"), cex=1, bty="n")
par(op)
```

----

```{r fivenets-1, cache=TRUE}
# Looking at one of the five networks
fivenets[[1]]
```

\pause How can we fit an ERGMito to this 5 networks?

## `ergmito` example (cont'd)

The same as you would do with the `ergm` package:

```{r fit-fivenets, cache=TRUE}
(model1 <- ergmito(fivenets ~ edges + nodematch("female")))
```

```{r fit-fivenets-print, results='asis', echo=FALSE, cache=TRUE}
texreg::texreg(model1)
# cat(gsub("#", "\\#", unclass(out), fixed=TRUE))
```

---


```{r gof-fivenets, cache=TRUE}
(gof1 <- gof_ergmito(model1))
```


---

```{r gof-fivenets-print, cache=TRUE, out.width=".7\\linewidth", fig.align='center', width=8, height=6}
plot(gof1)
```


## Simulation Study
			
			
We conducted a simulation study to explore the properties of MLE for small networks (a.k.a. ERGMito). To generate each sample of teams:\pause

1. Draw the **population parameters** from a piecewise Uniform with values in $[-4, -.1]\cup[.1, 4]$\pause

2. We will draw **groups of sizes 3 to 5**. The number of networks per group size are drawn from a Poisson distribution with parameter 10 (hence, an expected size of 30 networks per sample).\pause

3. Use the **drawn parameters** and **group sizes** to **generate random graphs** using an ERGM data generating process.\pause

We simulated 100,000 samples, each one composed of an average of 30 networks.

## Simulation Study (cont'd)

\begin{figure}
\centering
\includegraphics[width=.55\linewidth]{fig/power-02-various-sizes-3-5.pdf}
\caption{Empirical power of Pooled-ERGM estimates at various levels of effect size. As expected, power increases significantly with sample size (\# of networks per sample). Interestingly, the discovery rate of an effect size within $[1, 2)$ is very high even with a sample size of 20-30 networks. More extreme points have higher volatility due to small number of samples included.}
\end{figure}

----

\large So now that we can estimate ERGMs for small networks (cool!)...\pause{}

\hspace{2cm}... what can this tell us about our 42 teams?

## Preliminary results

```{r preleminary-results, echo=FALSE, results='asis', warning=FALSE, message=FALSE, cache=TRUE, small=FALSE}

library(ergmito)
library(magrittr)
library(texreg)

# final      <- readRDS("ci-and-ergms-models/ergmito_final.rds")
influence  <- readRDS("ci-and-ergms-models/ergmito_influence_final.rds")
leadership <- readRDS("ci-and-ergms-models/ergmito_leader_final.rds")
advice     <- readRDS("ci-and-ergms-models/ergmito_advice_final.rds")$`RME+Female+SI3Fac1`

# Subseting the models that Kayla presented in the Review
list(
  Advice     = advice,
  Influence  = influence$`T. Triad`,
  Leadership = leadership$`T. Triad`
) %>% 
  texreg(
    caption = paste(
      "The two statistics that showed to be the most robust were \\textbf{Indeg. RME}",
      "and \\textbf{Outdeg. Female}. These two effects can be described as (1)",
      "individuals with high levels of RME receive more ties, and (2) female",
      "subjects were more likely of seeking advice than male. Other statistics",
      "such as GPA, religiousness, age, and ethnicity were not significant."
      ),
    custom.coef.names = c(
      "Edges", "Transitive Triads", "Indeg. RME", "Outdeg. Female", "Outdeg. Social Accomodation", "Indeg. Female"
    ))

```

----

```{r preliminary-results-gof-advice, width=9, height=6, out.width=".75\\linewidth", echo=FALSE, eval=TRUE, cache=FALSE, fig.align='center'}
library(ergmito)
plot(gof_ergmito(advice), main = "Goodness-of-fit Statistics", sub = "Advice Seeking Network")
```

----

```{r preliminary-results-gof-influence, width=9, height=2, out.width=".75\\linewidth", echo=FALSE, eval=TRUE, cache=FALSE, fig.align='center'}
library(ergmito)
plot(gof_ergmito(influence$`T. Triad`), main = "Goodness-of-fit Statistics", sub = "Influence Network")
```

----

```{r preliminary-results-gof-ledership, width=9, height=2, out.width=".75\\linewidth", echo=FALSE, eval=TRUE, cache=FALSE, fig.align='center'}
library(ergmito)
plot(gof_ergmito(leadership$`T. Triad`), main = "Goodness-of-fit Statistics", sub = "Leadership Network")
```

# Part II: Association between network structure and team performance

## Testing effects of social network structure on group performance
			
Two common approaches: Generalized Linear Models (GLMs), or permutation-like tests. Both have limitations:\pause
	
- GLMs:\pause
    
    - Sample size is problematic: How costly is getting enough teams to run get a desired level of power?\pause

- Permutation-like tests:\pause
    
    - Permutation: shuffle the dependent variable and compute, for example, correlations.\pause{} \textcolor{USCCardinal}{\textbf{Which does not control for other factors in the system.}}\pause
    
    - Rewiring [see @Milo2004]: Sample networks by generating new graphs using a rewiring algorithm, usually preserving some property such as degree sequence--the observed sequence of in/out degree.\pause \textcolor{USCCardinal}{\textbf{This assumes an oversimplifying data generating process.}}\pause{} And worse, in a network of size 4, how many different networks can be observed **holding the degree sequence fixed**?

\pause BTW: Talking about Degree sequence leads directly to the now controvelsial Scale-free networks.
  
---

**"Scale-free networks are rare"**

> \Huge"\normalsize The **structural diversity of real-world networks** uncovered here presents both a puzzle and an opportunity. The strong focus in the scientific literature on **explaining and exploiting scale-free patterns has meant relatively less is known about mechanisms that produce non-scale-free structural patterns**, e.g., those with degree distributions better fitted by a log-normal. Two important directions of future work will be the **development and validation of novel mechanisms for generating more realistic degree structure in networks**, and novel statistical techniques for identifying or untangling them given empirical data\Huge"\normalsize

\raggedleft
-- **p. 8, @broido2019**

\raggedright
See @Holme2019 for a recent reference on the Scale-free issue.
  
## An Idea

What about using ERGMs to generate null distributions?\pause

- Even for small networks, we can generate thousands of unique graphs, so sample size is not a problem.\pause

- As a difference from permutation tests:\pause
    
    - ERGMs provide a more meaningful/realistic (or comprehensive if you like) data generating process\pause
      
    - On average, sampled networks will **look like the original** graph (addressing @broido2019's comments).\pause


In principle, this would be equivalent to a revised rewiring test...

<!-- ## A semiparametric test -->

<!-- **Notation** -->

<!-- - $\Graph = \{\graph_j\}$ is a sequence of $J$ graphs that share a common data-generating-process, e.g. teams formed in a lab. -->

<!-- - Each network has node-level attributes $x \in \mathcal{X}$. -->

<!-- - A group(graph) level outcome variable, such as team performance, $Y$. -->

<!-- - Under the null, network structure and group performance are not associated, this is $Y\perp\Graph$. -->

<!-- ## An Idea (cont'd) -->

<!-- -   Ideally, we would like to build a test with the following rationale\pause -->

<!--     $$ -->
<!--     \underbrace{\Graph \perp \Depvar}_{\mbox{Null assumption}} -->
<!--     \implies \ExpectedCond{\Depvar}{\Graph = \graph} =  -->
<!--     \Expected{\Depvar} -->
<!--     $$\pause -->

<!-- -   But this is not feasible without making strong distributional assumptions.\pause -->

<!-- -   Instead, we can take a look at the joint distribution of $(\Depvar, \Graph)$ conditioning on $\Depvar$ as follows:\pause -->

<!--     \begin{align*} -->
<!--     \hphantom{\underbrace{\Graph \perp \Depvar}_{\mbox{Null hypothesis}}} -->
<!--     & \implies \ExpectedCond{s(\Graph, \Depvar)}{\Graph = \graph} =  -->
<!--     \Expected{s(\Graph, \Depvar)} \\ -->
<!--     & \implies \underbrace{\ExpectedCond{s(\Graph, \Depvar)}{\Graph = \graph, \Depvar = \depvar}}_{\mbox{Observed statistic}} =  -->
<!--     \underbrace{\ExpectedCond{s(\Graph, \Depvar)}{\Depvar = \depvar}}_{Unobserved...} -->
<!--     \end{align*}\pause -->

<!--     Under the null, we can generate approximate the distribution of $\ExpectedCond{s(\Graph, \Depvar)}{\Depvar = \depvar}$ by simulations, in particular, drawing samples of new graphs (ERGMs). -->

## Algorithm

1.  Estimate an ERGM (estimates can come from a single graph or pooled estimates). We denote the data-generating-process of this model as $\mathcal{D}: \Theta\times \mathcal{X}\mapsto \GRAPH$.\pause

2.  Calculate the value $t_0 = t(\Graph, Y)$, the observed test statistic (e.g. correlation between triads and $\depvar$).\pause

3.  Now, for $b \in \{1, \dots, B\}$ do:\pause
    
    1.  For each group $j$ in $\{1, \dots, J\}$, draw a new network $\graph_j^b\sim\mathcal{D}(\hat{\theta}, X_j)$, this new sequence is denoted $\Graph^b$\pause
    
  	2.  Using $\Graph^b$ and $Y$, calculate $t_b = t(\Graph^b, Y)$\pause
  	
  	3.  Next $b$.\pause

This will generate a null distribution for the statistic $t$, which we can use to compare against the observed statistic, $t_0$.\pause

\alert{Note} An important distinction to make is that structures that gave origin to the graph need not to be relevant for the team's performance *per se*.
					
## Illustrated example

Suppose that we have a 3 networks of sizes 4, 4, and 5 respectively. The 

\footnotesize

\def\svgwidth{.8\linewidth}
\begin{figure}
\centering
\input{fig/struct-test.pdf_tex}
\end{figure}

\normalsize

We can use the distribution of the sequence $\{t_1, \dots, t_B\}$ as null to compare against $t_0$

## Extended example with `fivenets`

```{r fivenets-sim-partII, echo=FALSE, cache=TRUE, message=FALSE, warning=FALSE}
library(ergmito)
library(gnet)
# Loading the fivents dataset. We actually know that data generating process,
# so we use these paramaters for the model
data(fivenets, package="ergmito")

# We will generate a group level variable that is related to the proportion of
# females in the group
set.seed(52)
# y <- count_stats(fivenets ~ nodeocov("female"))
# y <- y + rnorm(nnets(fivenets))
y <- structure(c(1.01380909984854, 0.605144783941265, 4.30851530552903, 
0.954760011709497, -0.133078830968053), .Dim = c(5L, 1L), .Dimnames = list(
    NULL, "nodeocov(\"female\")"))

# Performing the struct test
f02 <- function(g, y) cor(count_stats(g ~ nodeocov("female")), y, use = "complete.obs")[1] 
test_struct <- struct_test(
  fivenets ~ edges + nodematch("female"), y = y, R=3000,
  stat = f02
  )
# mytest02

x <- count_stats(fivenets ~ nodeocov("female"))
test_ols <- summary(lm(y ~ x))
```

Going back to our `fivenets` example: \pause

- Recall that our data-generating process for $\Graph$ was an ERGMito with parameters $\left(\theta_{edges}, \theta_{\mbox{\texttt{nodematch("female")}}}\right)$.\pause

- Imagine that $\depvar_\graph = \sufstats{\graph} + \varepsilon$, with $\varepsilon\sim N(0,1)$ and $\sufstats{\graph}$ as the number of ties sent to women (`nodeicov("female")` in `ergm`)\pause

- Our test statistic $t$ is the correlation between $\depvar$ and $\sufstats{\graph}$\pause

- The data looks something like this\pause

```{r fivenets-print-partII, echo=FALSE, cache=TRUE}
knitr::kable(data.frame(
  y = unname(y),
  `nodeicov("female")` = unname(count_stats(fivenets ~ nodeicov("female"))),
  check.rows = FALSE
), col.names = c("y", "s(g)"))
```

---

We will try to assess the presence/absence of an association between the outcome $\depvar$ and the number of ties received by women, `nodeicov("female")`, using both a linear regression model and our test\pause

-   *Our approach* Is the the observed correlation statistic $t_0 = \mbox{cor}\left(y, \sufstats{\graph}\right)$ different than as expected by chance (assuming $\graph$ follows an ERGM distribution)?\pause

-   *OLS approach* In the following model:\pause

    $$
    \depvar = \alpha + \theta^{OLS}\sufstats{\graph} + \varepsilon,\quad\varepsilon\sim N(0,1)
    $$
    is the $\theta_{OLS}$ parameter significantly different from zero?
    

## Extended example with `fivenets` (cont'd)

\begin{figure}
\centering

```{r fivenets-print-results-partII, echo=FALSE, fig.width=10, fig.height=6, out.width='.7\\linewidth'}
op <- par(mfrow=c(1, 2))
hist(test_struct$t, breaks=50, col="gray", border="transparent", main = "Null distribution of t",
     xlab = "Values of t")
abline(v = test_struct$t0, col="steelblue", lwd=2, lty="dashed")
plot(y ~ x, main = "Linear regression", xlab="s(g)", ylab = "y")
abline(lm(y~x), lty="dashed", lwd=2)
par(op)
```

\caption{Comparing our method against a linear regression. Our proposed method returned a two sided p-value of `r sprintf("%05.3f", test_struct$pvalue)`, while the pvalue for the OLS coefficient was `r sprintf("%05.3f", test_ols$coefficients["x", "Pr(>|t|)"])`.}
\end{figure}

## Concluding remarks

Exponential Random Graph Models for Small Networks:\pause

1.  Not a new thing,\pause{} what's new is the tool to do so in a smooth way.\pause

2.  Preliminary results (both from simulations and applications) look encouraging.\pause

2.  Still work to do (on the development side of things): Goodness of fit tests, better algorithms for drawing random graphs, Bayesian models \pause (because is *great* fun...), etc.\pause

3.  Can be extended to other types of ERGMs... our next target: TERGMs (Separable Exponential Random Graph Models)\pause

Test for Association between graph level outcomes and graph structures:\pause

1.  Still need to run simulation studies to explore **power** and **false discovery** rates.\pause

2.  Also on the development side of things, need to make things a bit faster and lightweight.\pause

3.  Working on a more formal statistical framework (when is it a good/bad idea to use this kind of method).



## Thanks!

\begin{centering}
\includegraphics[width = .1\linewidth]{usc.pdf}

\large \textbf{\textcolor{USCCardinal}{George G. Vega Yon}}

\normalsize Let's chat! 

\href{mailto:vegayon@usc.edu}{vegayon@usc.edu} 

\href{https://ggvy.cl}{https://ggvy.cl} 

\includegraphics[width=.02\linewidth]{github.png}\href{https://github.com/gvegayon}{@gvegayon}

\includegraphics[width=.02\linewidth]{twitter.png}\href{https://twitter.com/gvegayon}{@gvegayon}

\end{centering}

## References {.allowframebreaks}
